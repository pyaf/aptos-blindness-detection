{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:41:36.789400Z",
     "start_time": "2019-08-22T14:41:35.584647Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert all images in a folder to npy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:41:55.410310Z",
     "start_time": "2019-08-22T14:41:55.375541Z"
    }
   },
   "outputs": [],
   "source": [
    "images = glob.glob('../data/aug_6/*')\n",
    "npy_folder = '../data/npy_files/aug_6'\n",
    "mkdir(npy_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:30:34.294554Z",
     "start_time": "2019-08-22T15:30:34.288924Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv2npy(path):\n",
    "    '''take jpeg/png convert them to resized npy image with same aspect ratio'''\n",
    "    image = Image.open(path)\n",
    "    w, h = image.size # pil returns w, h\n",
    "#     image = image.resize((256, int(h/w * 256))) # w, h\n",
    "#     w, h = image.size\n",
    "    if h > w:\n",
    "        r = w/h\n",
    "        image = image.resize((int(w/h * 256), 256)) # w, h\n",
    "#         print(path)\n",
    "        filename = Path(path).stem\n",
    "        np.save(os.path.join('../data/npy_files/aug_6', filename + '.npy'), np.array(image))\n",
    "    \n",
    "# pil image.size returns w, h, np.array/ cv2 return h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:30:14.087413Z",
     "start_time": "2019-08-22T15:25:37.008183Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/aug_6/42394_right.jpeg\n",
      "../data/aug_6/41535_right.jpeg\n",
      "../data/aug_6/8215_right.jpeg\n",
      "../data/aug_6/22462_left.jpeg\n",
      "../data/aug_6/188219f2d9c6.png\n",
      "../data/aug_6/3206_right.jpeg\n",
      "../data/aug_6/37586_right.jpeg\n",
      "../data/aug_6/28355_right.jpeg\n",
      "../data/aug_6/24559_right.jpeg\n",
      "../data/aug_6/23380_right.jpeg\n",
      "../data/aug_6/32711_left.jpeg\n",
      "../data/aug_6/20032_left.jpeg\n",
      "../data/aug_6/18254_right.jpeg\n",
      "../data/aug_6/748_right.jpeg\n",
      "../data/aug_6/15665_left.jpeg\n",
      "../data/aug_6/769_right.jpeg\n",
      "../data/aug_6/748_left.jpeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6e67254e5892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mconv2npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3c69027ed87c>\u001b[0m in \u001b[0;36mconv2npy\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;31m# pil returns w, h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# w, h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for path in images:\n",
    "    conv2npy(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-22T15:30:37.104Z"
    }
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.map(conv2npy, images)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:34:25.425857Z",
     "start_time": "2019-08-22T14:34:25.419918Z"
    }
   },
   "outputs": [],
   "source": [
    "image.size, np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:36:08.658293Z",
     "start_time": "2019-08-22T14:36:08.525214Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = images[8318]\n",
    "path = os.path.join(npy_folder, filename + '.npy')\n",
    "img = np.load(path)\n",
    "plt.imshow(img)\n",
    "print(path, img.shape)\n",
    "# plt.imshow(np.array(Image.open(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:13:13.645828Z",
     "start_time": "2019-08-22T09:13:13.361853Z"
    }
   },
   "outputs": [],
   "source": [
    "# read all three data labels files\n",
    "train1 = pd.read_csv('../data/train.csv')\n",
    "train2 = pd.read_csv('../data/2015.csv')\n",
    "train3 = pd.read_csv('../data/train_messidor.csv')\n",
    "train4 = pd.read_csv('../external_data/IDRiD/idrid.csv')\n",
    "train5 = pd.read_csv('../external_data/messidor-2/messidor_data.csv')\n",
    "test = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T08:36:08.555417Z",
     "start_time": "2019-08-21T08:36:08.548568Z"
    }
   },
   "outputs": [],
   "source": [
    "train3['diagnosis'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:06:39.825543Z",
     "start_time": "2019-08-20T20:06:39.810472Z"
    }
   },
   "outputs": [],
   "source": [
    "train5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:11:15.044562Z",
     "start_time": "2019-08-20T20:11:15.038162Z"
    }
   },
   "outputs": [],
   "source": [
    "train5['ext'] = train5['image_id'].apply(lambda x: x.split('.')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:13:45.736627Z",
     "start_time": "2019-08-20T20:13:45.730529Z"
    }
   },
   "outputs": [],
   "source": [
    "gb = train5.groupby('ext')\n",
    "train5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:11:58.729991Z",
     "start_time": "2019-08-20T20:11:58.726981Z"
    }
   },
   "outputs": [],
   "source": [
    "png = gb.get_group('png')\n",
    "png.shape, train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:12:32.621216Z",
     "start_time": "2019-08-20T20:12:32.618249Z"
    }
   },
   "outputs": [],
   "source": [
    "jpg = gb.get_group('jpg')\n",
    "jpg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:14:13.790434Z",
     "start_time": "2019-08-20T20:14:13.783233Z"
    }
   },
   "outputs": [],
   "source": [
    "jpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T20:14:58.774368Z",
     "start_time": "2019-08-20T20:14:58.643472Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../external_data/messidor-2/' + jpg.iloc[0]['image_id']\n",
    "img = cv2.imread(path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:41:34.892396Z",
     "start_time": "2019-08-20T18:41:34.886001Z"
    }
   },
   "outputs": [],
   "source": [
    "train4['diagnosis'].value_counts(), train4.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:43:02.951345Z",
     "start_time": "2019-08-20T18:42:51.819357Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    path = '../data/all_images/' + train2.iloc[i]['id_code']\n",
    "    img = cv2.imread(path)\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:43:40.744192Z",
     "start_time": "2019-08-20T18:43:40.484969Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:41:38.762666Z",
     "start_time": "2019-08-20T18:41:38.756650Z"
    }
   },
   "outputs": [],
   "source": [
    "# train5.apply(lambda x: print(f'mv test/{x[0]}.jpg test/test{x[0]}.jpg'), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T17:53:42.146577Z",
     "start_time": "2019-08-20T17:53:42.106465Z"
    }
   },
   "outputs": [],
   "source": [
    "# concatenate into one\n",
    "train1['path'] = train1['id_code'].apply(lambda x: \"../data/all_images/\" + x)\n",
    "#test['path'] = test['id_code'].apply(lambda x: \"../data/test_images/\" + x)\n",
    "train2['path'] = train2['id_code'].apply(lambda x: \"../data/all_images/\" + x)\n",
    "train3['path'] = train3['id_code'].apply(lambda x: \"../data/all_images/\" + x)\n",
    "train_df = pd.concat([train1, train2, train3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:53:28.847390Z",
     "start_time": "2019-08-19T06:53:28.839283Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T09:26:48.086144Z",
     "start_time": "2019-08-13T09:26:48.066739Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_rgb(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image\n",
    "\n",
    "def load_ben_color(path, size, sigmaX=10, crop=False):\n",
    "    \"\"\"if crop=True: center crop retina\"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if crop:\n",
    "        image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(\n",
    "        image, (0, 0), sigmaX), -4, 128)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_ben_color_cropped(path, IMG_SIZE, sigmaX=10, tol=8):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image, tol=tol)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "    return image\n",
    "\n",
    "def load_ben_gray(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.addWeighted(\n",
    "       image, 4, cv2.GaussianBlur(image, (0, 0), IMG_SIZE / 10), -4, 128\n",
    "    )  # Ben Graham's preprocessing method [1]\n",
    "    ## (IMG_SIZE, IMG_SIZE) -> (IMG_SIZE, IMG_SIZE, 3)\n",
    "    image = image.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    image = np.repeat(image, 3, axis=-1)\n",
    "    return image\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "#     pdb.set_trace()\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:53:48.085062Z",
     "start_time": "2019-08-19T06:53:48.024316Z"
    }
   },
   "outputs": [],
   "source": [
    "names = train_df.id_code.values\n",
    "#names = test.id_code.values\n",
    "save_folder = '../data/npy_files/'\n",
    "IMG_SIZE = 456\n",
    "mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:34:01.241662Z",
     "start_time": "2019-08-10T10:34:01.239097Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T09:27:39.457657Z",
     "start_time": "2019-08-13T09:27:39.450922Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T09:30:24.259902Z",
     "start_time": "2019-08-13T09:28:39.840550Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this thing is slow at start (the png and tif images) then speeds up after ~5k iterations (the jpegs)\n",
    "for idx, row in tqdm(test.iterrows()):\n",
    "    image = load_ben_color_cropped(row.path, IMG_SIZE, tol=10)\n",
    "    np.save(os.path.join(save_folder, row.id_code + '.npy'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T09:27:11.990165Z",
     "start_time": "2019-08-13T09:27:11.986390Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = test.iloc[0]['id_code']\n",
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T09:27:13.862931Z",
     "start_time": "2019-08-13T09:27:13.710427Z"
    }
   },
   "outputs": [],
   "source": [
    "image = np.load(f'../data/npy_files/bgcc456/{fname}.npy')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T20:00:44.308885Z",
     "start_time": "2019-07-14T20:00:44.114225Z"
    }
   },
   "outputs": [],
   "source": [
    "npy_files = glob('../data/train_images/npy_bengrahm_color/*.npy')\n",
    "npy = np.random.choice(npy_files)\n",
    "print(npy)\n",
    "image = np.load(npy)\n",
    "plt.imshow(image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T06:46:13.036139Z",
     "start_time": "2019-07-15T06:46:12.673562Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx=0\n",
    "idx+=1\n",
    "#print(idx)\n",
    "#fname = names[idx]\n",
    "fname = \"20060523_50153_0100_PP\"\n",
    "image_folder = '../external_data/messidor/train_images/'\n",
    "img_path = os.path.join(images_folder, fname + \".tif\")\n",
    "image_org = load_ben_color(img_path)\n",
    "image_cropped = load_ben_color_cropped(img_path, tol=10)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_org, cmap=\"gray\")\n",
    "label = ''\n",
    "#label = str(train_df.iloc[idx]['diagnosis'])\n",
    "plt.title('label: ' + label)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_cropped, cmap=\"gray\")\n",
    "plt.title('label: ' + label) \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T06:38:34.165780Z",
     "start_time": "2019-07-15T06:38:34.138276Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "mask = gray_img> 8 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T06:38:35.066308Z",
     "start_time": "2019-07-15T06:38:34.953177Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "    return img # return original image\n",
    "else:\n",
    "    img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "    img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "    img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "#         print(img1.shape,img2.shape,img3.shape)\n",
    "    img = np.stack([img1,img2,img3],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  save all npy files in one npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:30:45.810832Z",
     "start_time": "2019-08-12T15:27:10.761886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images = []  # because small dataset.\n",
    "train1 = pd.read_csv('../data/test.csv')\n",
    "fnames = train1.id_code.tolist()\n",
    "for fname in tqdm(fnames):\n",
    "    path = os.path.join('../data/test_images/', fname + '.png')\n",
    "    image = load_ben_color(path, size=456, crop=True)\n",
    "#     path = os.path.join('../data/npy_files/bgcc456/' + fname + '.npy')\n",
    "#     image = np.load(path)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:31:01.085612Z",
     "start_time": "2019-08-12T15:30:50.705371Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/npy_files/all_test_bgcc456.npy', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### messidor xls to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T18:58:31.363159Z",
     "start_time": "2019-07-14T18:58:30.905647Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combining messidors label xls files into a csv file\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# filenames\n",
    "excel_names = glob('../external_data/messidor/*.xls')\n",
    "\n",
    "# read them in\n",
    "excels = [pd.ExcelFile(name) for name in excel_names]\n",
    "\n",
    "# turn them into dataframes\n",
    "frames = [x.parse(x.sheet_names[0], header=None,index_col=None) for x in excels]\n",
    "\n",
    "# delete the first row for all frames except the first\n",
    "# i.e. remove the header row -- assumes it's the first\n",
    "frames[1:] = [df[1:] for df in frames[1:]]\n",
    "\n",
    "# concatenate them..\n",
    "combined = pd.concat(frames)\n",
    "\n",
    "# write it out\n",
    "#combined.to_excel(\"c.xlsx\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T18:58:36.195865Z",
     "start_time": "2019-07-14T18:58:36.189724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T18:58:48.177220Z",
     "start_time": "2019-07-14T18:58:48.174474Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T18:59:17.984349Z",
     "start_time": "2019-07-14T18:59:17.966076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined.to_csv('../external_data/messidor/train.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined['id_code'] = combined['Image name'].apply(lambda x: x.split('.')[0])\n",
    "combined['diagnosis'] = combined['Retinopathy grade']\n",
    "combined = combined.drop(columns=['Image name', 'Ophthalmologic department', 'Retinopathy grade', 'Risk of macular edema '], axis=0)\n",
    "combined.to_csv('../external_data/messidor/combinedsidor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test images sizes of the data prepared so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# !ls ../data/train_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T06:50:15.433425Z",
     "start_time": "2019-08-10T06:50:15.270102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = np.load('../data/train_images/npy_bengrahm_color/000c1434d8d7.npy')\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T06:53:34.135587Z",
     "start_time": "2019-08-10T06:53:33.970843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = np.load('../data/train_images/bgcc300/000c1434d8d7.npy')\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### copy files to class wise directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T12:55:50.029539Z",
     "start_time": "2019-08-17T12:55:50.022707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T13:03:35.665279Z",
     "start_time": "2019-08-17T13:03:35.434905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train1.apply(lambda x: print(f'cp all_images/{x[0]} class_wise/class_{x[1]}'), axis=1); # expand this, copy with keyboard ctrl+shift whatever, paste in a bash file, run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:13.074395Z",
     "start_time": "2019-08-22T09:14:12.992616Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "# functions\n",
    "\n",
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Crop out black borders\n",
    "    https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping\n",
    "    \"\"\"\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1), mask.any(0))]\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
    "        if (check_shape == 0):\n",
    "            return img\n",
    "        else:\n",
    "            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img = np.stack([img1, img2, img3], axis=-1)\n",
    "        return img\n",
    "\n",
    "def scaleRadius(img,scale):\n",
    "    \"\"\"\n",
    "    Part of Ben's technique\n",
    "    https://github.com/btgraham/SparseConvNet/blob/kaggle_Diabetic_Retinopathy_competition/competitionreport.pdf\n",
    "    \"\"\"\n",
    "    x=img[int(img.shape[0]/2),:,:].sum(1)\n",
    "    r=(x>x.mean()/10).sum()/2\n",
    "    s=scale*1.0/r\n",
    "    return cv2.resize(img, (0,0), fx=s,fy=s)\n",
    "\n",
    "def aug_0(img_path):\n",
    "    \"\"\"\n",
    "    Crop black area\n",
    "    \"\"\"\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = crop_image_from_gray(img)\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_0/{}'.format(\n",
    "            os.path.basename(img_path)), img)\n",
    "\n",
    "\n",
    "def aug_1(img_path):\n",
    "    \"\"\"\n",
    "    Ben's technique\n",
    "    https://github.com/btgraham/SparseConvNet/blob/kaggle_Diabetic_Retinopathy_competition/competitionreport.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    scale = 300\n",
    "\n",
    "    a = cv2.imread(img_path)\n",
    "    a = scaleRadius(a, scale)\n",
    "    a = cv2.addWeighted(a, 4, cv2.GaussianBlur(a, (0, 0), scale/30), -4, 128)\n",
    "    b = np.zeros(a.shape)\n",
    "    cv2.circle(b,(int(a.shape[1]/2), int(a.shape[0]/2)), int(scale*0.9),(1,1,1),-1,8,0)\n",
    "    a = a*b-128*(1-b)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_1/{}'.format(\n",
    "            os.path.basename(img_path)), a)\n",
    "\n",
    "\n",
    "def aug_2(img_path):\n",
    "    \"\"\"\n",
    "    Ben's technique with median blur\n",
    "    https://github.com/btgraham/SparseConvNet/blob/kaggle_Diabetic_Retinopathy_competition/competitionreport.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    scale = 300\n",
    "\n",
    "    a = cv2.imread(img_path)\n",
    "    a = scaleRadius(a, scale)\n",
    "\n",
    "    k = np.min(a.shape[0:2]) // 20 * 2 + 1\n",
    "\n",
    "    a = cv2.addWeighted(a, 4, cv2.medianBlur(a, k), -4, 128)\n",
    "    b = np.zeros(a.shape)\n",
    "    cv2.circle(b,(int(a.shape[1]/2), int(a.shape[0]/2)), int(scale*0.9),(1,1,1),-1,8,0)\n",
    "    a = a*b-128*(1-b)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_2/{}'.format(\n",
    "            os.path.basename(img_path)), a)\n",
    "\n",
    "\n",
    "def aug_3(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE and then stack the green channel\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = image[:, :, 1]\n",
    "\n",
    "    image = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(image)\n",
    "    image = np.dstack((image, image, image))\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '../data/aug_3/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "def aug_4(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE, median blur and then stack the green channel\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    image = image[:, :, 1]\n",
    "    image = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(image)\n",
    "    image = np.dstack((image, image, image))\n",
    "\n",
    "    k = np.min(image.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(image, k)\n",
    "    image = cv2.addWeighted(image, 4, bg, -4, 128)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ags/DATA/CODE/kaggle/aptos2019-blindness-detection/data/aug_4/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "\n",
    "def aug_5(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE to all channels\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    lab[..., 0] = clahe.apply(lab[..., 0])\n",
    "    image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_5/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "def aug_6(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE to all channels with median blur\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    lab[..., 0] = clahe.apply(lab[..., 0])\n",
    "    image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    k = np.min(image.shape[0:2]) // 25 * 2 + 1\n",
    "    bg = cv2.medianBlur(image, k)\n",
    "    image = cv2.addWeighted(image, 4, bg, -4, 128)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ags/DATA/CODE/kaggle/aptos2019-blindness-detection/data/aug_6/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "def aug_7(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, dissect into 4, apply CLAHE, median blur and then stack the green channel\n",
    "    Based on https://www.sciencedirect.com/science/article/pii/S2212017313005781\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    height, width, depth = image.shape\n",
    "\n",
    "    image = image[:, :, 1]\n",
    "\n",
    "    q1 = image[0:int(height / 2), 0:int(width / 2)]\n",
    "    q2 = image[0:int(height / 2), int(width / 2):]\n",
    "    q3 = image[int(height / 2):, 0:int(width / 2)]\n",
    "    q4 = image[int(height / 2):, int(width / 2):]\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    q1 = clahe.apply(q1)\n",
    "    k = np.min(q1.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q1, k)\n",
    "    q1 = cv2.addWeighted(q1, 4, bg, -4, 128)\n",
    "\n",
    "    q2 = clahe.apply(q2)\n",
    "    k = np.min(q2.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q2, k)\n",
    "    q2 = cv2.addWeighted(q2, 4, bg, -4, 128)\n",
    "\n",
    "    q3 = clahe.apply(q3)\n",
    "    k = np.min(q3.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q3, k)\n",
    "    q3 = cv2.addWeighted(q3, 4, bg, -4, 128)\n",
    "\n",
    "    q4 = clahe.apply(q4)\n",
    "    k = np.min(q4.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q4, k)\n",
    "    q4 = cv2.addWeighted(q4, 4, bg, -4, 128)\n",
    "\n",
    "    h1 = np.concatenate((q1, q2), axis=1)\n",
    "    h2 = np.concatenate((q3, q4), axis=1)\n",
    "    image = np.concatenate((h1, h2), axis=0)\n",
    "\n",
    "    image = np.dstack((image, image, image))\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_7/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "\n",
    "def aug_8(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, dissect into 4, apply CLAHE, median blur across all channels\n",
    "    Based on https://www.sciencedirect.com/science/article/pii/S2212017313005781\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    height, width, depth = image.shape\n",
    "\n",
    "    q1 = image[0:int(height / 2), 0:int(width / 2)]\n",
    "    q2 = image[0:int(height / 2), int(width / 2):]\n",
    "    q3 = image[int(height / 2):, 0:int(width / 2)]\n",
    "    q4 = image[int(height / 2):, int(width / 2):]\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    q1 = cv2.cvtColor(q1, cv2.COLOR_BGR2LAB)\n",
    "    q1[..., 0] = clahe.apply(q1[..., 0])\n",
    "    q1 = cv2.cvtColor(q1, cv2.COLOR_LAB2BGR)\n",
    "    k = np.min(q1.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q1, k)\n",
    "    q1 = cv2.addWeighted(q1, 4, bg, -4, 128)\n",
    "\n",
    "    q2 = cv2.cvtColor(q2, cv2.COLOR_BGR2LAB)\n",
    "    q2[..., 0] = clahe.apply(q2[..., 0])\n",
    "    q2 = cv2.cvtColor(q2, cv2.COLOR_LAB2BGR)\n",
    "    k = np.min(q2.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q2, k)\n",
    "    q2 = cv2.addWeighted(q2, 4, bg, -4, 128)\n",
    "\n",
    "    q3 = cv2.cvtColor(q3, cv2.COLOR_BGR2LAB)\n",
    "    q3[..., 0] = clahe.apply(q3[..., 0])\n",
    "    q3 = cv2.cvtColor(q3, cv2.COLOR_LAB2BGR)\n",
    "    k = np.min(q3.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q3, k)\n",
    "    q3 = cv2.addWeighted(q3, 4, bg, -4, 128)\n",
    "\n",
    "    q4 = cv2.cvtColor(q4, cv2.COLOR_BGR2LAB)\n",
    "    q4[..., 0] = clahe.apply(q4[..., 0])\n",
    "    q4 = cv2.cvtColor(q4, cv2.COLOR_LAB2BGR)\n",
    "    k = np.min(q4.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(q4, k)\n",
    "    q4 = cv2.addWeighted(q4, 4, bg, -4, 128)\n",
    "\n",
    "    h1 = np.concatenate((q1, q2), axis=1)\n",
    "    h2 = np.concatenate((q3, q4), axis=1)\n",
    "    image = np.concatenate((h1, h2), axis=0)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_8/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "\n",
    "def aug_9(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE to all channels without converting to LAB\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    image[..., 0] = clahe.apply(image[..., 0])\n",
    "    image[..., 1] = clahe.apply(image[..., 1])\n",
    "    image[..., 2] = clahe.apply(image[..., 2])\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_9/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n",
    "\n",
    "def aug_10(img_path):\n",
    "    \"\"\"\n",
    "    Cropping, apply CLAHE to all channels without converting to LAB, then apply median\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = crop_image_from_gray(image)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    image[..., 0] = clahe.apply(image[..., 0])\n",
    "    image[..., 1] = clahe.apply(image[..., 1])\n",
    "    image[..., 2] = clahe.apply(image[..., 2])\n",
    "\n",
    "    k = np.min(image.shape[0:2]) // 20 * 2 + 1\n",
    "    bg = cv2.medianBlur(image, k)\n",
    "    image = cv2.addWeighted(image, 4, bg, -4, 128)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        '/media/ains/dec4dfd1-4e1b-4f58-8203-1e4a2fb67acf/preprocessing_experiment/aug_10/{}'.format(\n",
    "            os.path.basename(img_path)), image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:13.286394Z",
     "start_time": "2019-08-22T09:14:13.282763Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def resampled(df, count_dict):\n",
    "    ''' resample from df with replace=False'''\n",
    "    def sample(obj):  # [5]\n",
    "        return obj.sample(n=count_dict[obj.name], replace=False, random_state=69)\n",
    "    sampled_df = df.groupby('diagnosis').apply(sample).reset_index(drop=True)\n",
    "    return sampled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:13.635419Z",
     "start_time": "2019-08-22T09:14:13.585729Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "train1 = pd.read_csv('../data/train.csv')\n",
    "train2 = pd.read_csv('../data/2015.csv')\n",
    "train3 = pd.read_csv('../data/train_messidor.csv')\n",
    "train4 = pd.read_csv('../data/idrid.csv')\n",
    "#count_dict = defaultdict(lambda: 1900)\n",
    "count_dict = {\n",
    "    0: 2000,\n",
    "    2: 2000,\n",
    "    1: 2000,\n",
    "    3: 2000,\n",
    "    4: 1914,\n",
    "}\n",
    "# df = resampled(train2, count_dict)\n",
    "# df = train2.append(resampled(train2, count_dict), ignore_index=True)\n",
    "# df = train3.append(train4, ignore_index=True)\n",
    "# df = df.append(train3, ignore_index=True)\n",
    "df = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:13.916409Z",
     "start_time": "2019-08-22T09:14:13.908327Z"
    }
   },
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:14.253584Z",
     "start_time": "2019-08-22T09:14:14.225822Z"
    }
   },
   "outputs": [],
   "source": [
    "df['path'] = df.apply(lambda x: '../data/test_images/' + x[0] + '.png', axis=1)\n",
    "# df['path'] = df.apply(lambda x: '../data/all_images/' + x[0], axis=1)\n",
    "images = df['path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:14:14.576614Z",
     "start_time": "2019-08-22T09:14:14.569196Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:15:43.882206Z",
     "start_time": "2019-08-22T09:14:15.101074Z"
    }
   },
   "outputs": [],
   "source": [
    "# use multiprocessing to create the images.\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.map(aug_6, images)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  modify labels in train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = '''\n",
    "2221cf5c7935.png, 0, 2\n",
    "2d07162a13b1.png, 0, 1\n",
    "4f0866b90c27.png, 3, 4\n",
    "772af553b8b7.png, 3, 4\n",
    "bf8092e4001d.png, 3, 4\n",
    "fcc6aa6755e6.png, 3, 4\n",
    "4f0866b90c27.png, 3, 4\n",
    "5b3e7197ac1c.png, 3, 4\n",
    "'''\n",
    "for id_ in ids.strip().split('\\n'):\n",
    "    id_  = id_.split(',')\n",
    "    name = id_[0]\n",
    "    new_label = int(id_[2])\n",
    "    idx = train1.query('id_code == \"%s\"' % name).index\n",
    "    print(train1.iloc[idx]['diagnosis'], new_label)\n",
    "#     train1.at[idx, 'diagnosis'] = new_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.to_csv('../data/train.csv', index=False)\n",
    "# original train.csv is already saved as train_org.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
