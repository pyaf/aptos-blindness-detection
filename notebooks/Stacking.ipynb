{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T09:05:01.715507Z",
     "start_time": "2019-08-16T09:05:01.703824Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "from glob import glob\n",
    "import torch\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from argparse import ArgumentParser\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "sys.path.append('..')\n",
    "from models import Model, get_model\n",
    "from utils import *\n",
    "from image_utils import *\n",
    "\n",
    "# from submission import get_best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T09:05:02.369594Z",
     "start_time": "2019-08-16T09:05:02.356527Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, root, df, size, mean, std, tta=4):\n",
    "        self.root = root\n",
    "        self.size = size\n",
    "        self.fnames = list(df[\"id_code\"])\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.tta = tta\n",
    "        self.TTA = albumentations.Compose(\n",
    "            [\n",
    "                # albumentations.RandomRotate90(p=1),\n",
    "                albumentations.Transpose(p=0.5),\n",
    "                albumentations.Flip(p=0.5),\n",
    "                albumentations.RandomScale(scale_limit=0.1),\n",
    "            ]\n",
    "        )\n",
    "        self.transform = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Normalize(mean=mean, std=std, p=1),\n",
    "                albumentations.Resize(size, size),\n",
    "                AT.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname + \".png\")\n",
    "\n",
    "        image = id_to_image(path,\n",
    "                    resize=True,\n",
    "                    size=self.size,\n",
    "                    augmentation=False,\n",
    "                    subtract_median=True,\n",
    "                    clahe_green=False\n",
    "                )\n",
    "\n",
    "        images = [self.transform(image=image)[\"image\"]]\n",
    "        for _ in range(self.tta):  # perform ttas\n",
    "            aug_img = self.TTA(image=image)[\"image\"]\n",
    "            aug_img = self.transform(image=aug_img)[\"image\"]\n",
    "            images.append(aug_img)\n",
    "        return torch.stack(images, dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "def get_predictions(model, testset, tta):\n",
    "    \"\"\"return all predictions on testset in a list\"\"\"\n",
    "    num_images = len(testset)\n",
    "    predictions = []\n",
    "    for i, batch in enumerate(tqdm(testset)):\n",
    "        if tta:\n",
    "            # images.shape [n, 3, 96, 96] where n is num of 1+tta\n",
    "            for images in batch:\n",
    "                preds = model(images.to(device))  # [n, num_classes]\n",
    "                predictions.append(preds.mean(dim=0).detach().tolist())\n",
    "        else:\n",
    "            preds = model(batch[:, 0].to(device))\n",
    "            preds = preds.detach().tolist()  # [1]\n",
    "            predictions.extend(preds)\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def get_load_model(model_name, ckpt_path, num_classes):\n",
    "    model = get_model(model_name, num_classes, pretrained=None)\n",
    "    state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "    epoch = state[\"epoch\"]\n",
    "    model.load_state_dict(state[\"state_dict\"])\n",
    "\n",
    "    best_thresholds = state[\"best_thresholds\"]\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, best_thresholds\n",
    "\n",
    "\n",
    "def get_model_name_fold(model_folder_path):\n",
    "    # example ckpt_path = weights/9-7_{modelname}_fold0_text/\n",
    "    model_folder = model_folder_path.split(\n",
    "        \"/\")[1]  # 9-7_{modelname}_fold0_text\n",
    "    model_name = \"_\".join(model_folder.split(\"_\")[1:-2])  # modelname\n",
    "    fold = model_folder.split(\"_\")[-2]  # fold0\n",
    "    fold = fold.split(\"f\")[-1]  # 0\n",
    "    return model_name, int(fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T09:08:11.841965Z",
     "start_time": "2019-08-16T09:08:11.564959Z"
    }
   },
   "outputs": [],
   "source": [
    "home = '/media/ags/DATA/CODE/kaggle/aptos2019-blindness-detection'\n",
    "model_name = \"efficientnet-b5\"\n",
    "ckpt_path_list = [\n",
    "    \"weights/168_efficientnet-b5_f0_poma/ckpt14.pth\",\n",
    "    \"weights/168_efficientnet-b5_f1_poma/ckpt14.pth\",\n",
    "    \"weights/168_efficientnet-b5_f2_poma/ckpt14.pth\",\n",
    "    \"weights/168_efficientnet-b5_f3_poma/ckpt14.pth\"\n",
    "#     \"weights/168_efficientnet-b5_f4_poma/ckpt14.pth\"\n",
    "]\n",
    "tta = 0\n",
    "size = 300\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "use_cuda = True\n",
    "num_classes = 1\n",
    "num_workers = 8\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "df = pd.read_csv(os.path.join(home,\"data/sample_submission.csv\"))\n",
    "root = os.path.join(home, \"data/test_images/\")\n",
    "testset = DataLoader(\n",
    "    Dataset(root, df, size, mean, std, tta),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True if use_cuda else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions using all models\n",
    "base_thresholds = np.array([0.5, 1.5, 2.5, 3.5])\n",
    "all_predictions = []\n",
    "for idx, ckpt in enumerate(ckpt_path_list):\n",
    "    print(\"model: %s\" % ckpt)\n",
    "    ckpt = os.path.join(home, ckpt)\n",
    "    model, val_best_th = get_load_model(model_name, ckpt, num_classes)\n",
    "    predictions = get_predictions(model, testset, tta)\n",
    "    preds = predict(predictions, base_thresholds)\n",
    "    print(np.unique(preds, return_counts=True)[1])\n",
    "    all_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean(all_predictions, axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(predictions, base_thresholds)\n",
    "print(np.unique(preds, return_counts=True)[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
